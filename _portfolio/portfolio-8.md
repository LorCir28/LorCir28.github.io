---
title: "Optimize Vision Transformers Architecture via Efficient Attention Modules: A Study on the Monocular Depth Estimation Task"
# excerpt: "Short description of portfolio item number 1<br/><img src='/images/500x300.png'>"
collection: portfolio
link: "https://github.com/LorCir28/optimized_vit.git"
---

ðŸ”‹ Official repository of the paper *Optimize Vision Transformers Architecture via Efficient Attention Modules: A Study on the Monocular Depth Estimation Task*.
Two modifications of METER attention module are proposed and implemented to build two more efficient versions: Meta-METER and Pyra-METER.